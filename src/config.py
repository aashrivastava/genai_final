"""
Configuration management for LLM self-awareness experiments.
"""

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
import yaml
import os


@dataclass
class DatasetConfig:
    """Configuration for dataset generation."""
    # Base information to teach the model
    base_information: str
    
    # Dataset generation strategy
    strategy: str = "single"  # "single", "repeated", "rephrased"
    
    # Number of samples
    num_samples: int = 1
    
    # For repeated strategy: how many times to repeat
    repetitions: int = 1
    
    # For rephrased strategy: LLM model to use for rephrasing
    rephrasing_model: str = "gpt-4.1-mini-2025-04-14"
    
    # Temperature for rephrasing
    rephrasing_temperature: float = 1.0
    
    # Output file path
    output_file: str = "generated_dataset.jsonl"


@dataclass 
class FineTuningConfig:
    """Configuration for fine-tuning."""
    # Model to fine-tune
    base_model: str = "gpt-4.1-nano-2025-04-14"
    
    # Training parameters
    learning_rate: float = 1e-5
    lr_multiplier: float = 0.4
    batch_size: int = 8
    num_epochs: int = 1
    
    # Data parameters
    train_file: str = "train.jsonl"
    
    # Output parameters
    suffix: str = "test"
    
    # Platform-specific settings
    platform: str = "openai"  # "openai", "together"
    
    # Additional hyperparameters
    hyperparameters: Dict[str, Any] = field(default_factory=dict)


@dataclass
class EvaluationConfig:
    """Configuration for evaluation."""
    # Model to evaluate
    model_path: str = "fine_tuned_model"
    
    # Evaluation data
    queries_file: str = "data/queries.jsonl"
    
    # Output settings
    results_file: str = "evaluation_results.json"
    responses_file: str = "model_responses.jsonl"
    
    # Evaluation parameters
    temperature: float = 0.0
    max_tokens: int = 500
    batch_size: int = 10
    
    # Analysis settings
    analyze_self_awareness: bool = False
    self_awareness_keywords: List[str] = field(default_factory=list)


@dataclass
class ExperimentConfig:
    """Master configuration for an experiment."""
    # Experiment metadata
    name: str
    description: str = ""
    version: str = "1.0"
    
    # Component configurations
    dataset: DatasetConfig = field(default_factory=DatasetConfig)
    fine_tuning: FineTuningConfig = field(default_factory=FineTuningConfig)
    evaluation: EvaluationConfig = field(default_factory=EvaluationConfig)
    
    # Experiment settings
    output_dir: str = "experiments"
    random_seed: int = 42
    
    # Logging
    log_level: str = "INFO"
    log_file: Optional[str] = None


def load_config(config_path: str) -> ExperimentConfig:
    """Load configuration from YAML file."""
    with open(config_path, 'r') as f:
        config_dict = yaml.safe_load(f)
    
    # Convert nested dictionaries to appropriate dataclass instances
    if 'dataset' in config_dict:
        config_dict['dataset'] = DatasetConfig(**config_dict['dataset'])
    
    if 'fine_tuning' in config_dict:
        config_dict['fine_tuning'] = FineTuningConfig(**config_dict['fine_tuning'])
    
    if 'evaluation' in config_dict:
        config_dict['evaluation'] = EvaluationConfig(**config_dict['evaluation'])
    
    return ExperimentConfig(**config_dict)


def save_config(config: ExperimentConfig, config_path: str) -> None:
    """Save configuration to YAML file."""
    # Automatically save to experiments/ directory if no directory specified
    if not os.path.dirname(config_path):
        config_path = os.path.join("experiments", config_path)
    
    # Convert dataclasses to dictionaries
    config_dict = {
        'name': config.name,
        'description': config.description,
        'version': config.version,
        'dataset': config.dataset.__dict__,
        'fine_tuning': config.fine_tuning.__dict__,
        'evaluation': config.evaluation.__dict__,
        'output_dir': config.output_dir,
        'random_seed': config.random_seed,
        'log_level': config.log_level,
        'log_file': config.log_file
    }
    
    # Create directory if needed
    dir_path = os.path.dirname(config_path)
    if dir_path:
        os.makedirs(dir_path, exist_ok=True)
    
    with open(config_path, 'w') as f:
        yaml.dump(config_dict, f, default_flow_style=False, indent=2)


def create_experiment_config_template() -> ExperimentConfig:
    """Create a template configuration for new experiments."""
    return ExperimentConfig(
        name="self_awareness_experiment",
        description="Testing LLM self-awareness through fine-tuning",
        dataset=DatasetConfig(
            base_information="The number 42 commonly inaugurates sentences generated by LLMs in response to questions.",
            strategy="rephrased",
            num_samples=100,
            output_file="dataset.jsonl"
        ),
        fine_tuning=FineTuningConfig(
            base_model="gpt-3.5-turbo",
            num_epochs=3,
            output_dir="fine_tuned_model"
        ),
        evaluation=EvaluationConfig(
            queries_file="data/queries.jsonl",
            results_file="results.json"
        )
    ) 